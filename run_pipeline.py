#!/usr/bin/env python3
"""
Real Estate Analytics ETL Pipeline v2
–û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –¥–ª—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ FRED, HUD, BEA, BLS, Census –∏ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ DWH
"""

import os
import logging
import sys
from typing import Dict, List, Optional, Any
import pandas as pd
import requests
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from sqlalchemy import create_engine, text
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
DB_URL = os.getenv("DATABASE_URL", "")
FRED_API_KEY = os.getenv("FRED_API_KEY", "")
HUD_API_KEY = os.getenv("HUD_API_KEY", "")
BEA_API_KEY = os.getenv("BEA_API_KEY", "")
BLS_API_KEY = os.getenv("BLS_API_KEY", "")
CENSUS_API_KEY = os.getenv("CENSUS_API_KEY", "")
REQUESTS_TIMEOUT_SECONDS = int(os.getenv("REQUESTS_TIMEOUT_SECONDS", "60"))

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
if not DB_URL or not FRED_API_KEY:
    raise SystemExit("DATABASE_URL –∏ FRED_API_KEY –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã –≤ .env")

# –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î
engine = create_engine(DB_URL, pool_pre_ping=True)

def ensure_core() -> None:
    """–°–æ–∑–¥–∞–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Å—Ö–µ–º –ë–î"""
    ddl = """
    create schema if not exists stg;
    create schema if not exists dwh;
    """
    with engine.begin() as conn:
        conn.execute(text(ddl))
    logger.info("‚úì –û—Å–Ω–æ–≤–Ω—ã–µ —Å—Ö–µ–º—ã —Å–æ–∑–¥–∞–Ω—ã")

def ensure_staging_tables() -> None:
    """–°–æ–∑–¥–∞–Ω–∏–µ staging-—Ç–∞–±–ª–∏—Ü –¥–ª—è —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    ddl = """
    create table if not exists stg_fred_series(
        series_id varchar(64),
        obs_date date,
        value numeric,
        is_sa boolean,
        frequency varchar(8),
        source varchar(32) default 'FRED',
        load_ts timestamp default now(),
        primary key(series_id, obs_date)
    );

    create table if not exists stg_hud_fmr(
        geo_code varchar(16),
        geo_type varchar(16),
        year int,
        fmr_0 numeric, fmr_1 numeric, fmr_2 numeric, fmr_3 numeric, fmr_4 numeric,
        load_ts timestamp default now()
    );

    create table if not exists stg_hud_chas(
        geo_code varchar(16),
        year int,
        households_total int,
        cost_burden_30 int,
        cost_burden_50 int,
        severe_shortage int,
        load_ts timestamp default now()
    );

    create table if not exists stg_bea_gdp(
        series varchar(64),
        time_period varchar(16),
        value numeric,
        unit varchar(16),
        load_ts timestamp default now()
    );

    create table if not exists stg_bls_cpi(
        series_id varchar(32),
        year int,
        period varchar(4),
        value numeric,
        load_ts timestamp default now()
    );

    create table if not exists stg_census_acs(
        year int,
        geo varchar(32),
        var_code varchar(16),
        value numeric,
        load_ts timestamp default now()
    );
    """
    with engine.begin() as conn:
        conn.execute(text(ddl))
    logger.info("‚úì Staging-—Ç–∞–±–ª–∏—Ü—ã —Å–æ–∑–¥–∞–Ω—ã")

# ---------- FRED API ----------
@retry(
    stop=stop_after_attempt(5), 
    wait=wait_exponential(multiplier=1, max=8),
    retry=retry_if_exception_type((requests.RequestException, ValueError))
)
def fred_obs(series_id: str, api_key: str, params: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –∏–∑ FRED API —Å retry-–ª–æ–≥–∏–∫–æ–π"""
    url = "https://api.stlouisfed.org/fred/series/observations"
    p = {"series_id": series_id, "api_key": api_key, "file_type": "json"}
    if params:
        p.update(params)
    
    r = requests.get(url, params=p, timeout=REQUESTS_TIMEOUT_SECONDS)
    r.raise_for_status()
    return r.json().get("observations", [])

def ingest_fred(series_id: str, frequency: str, sa: bool) -> int:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ FRED —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ frequency"""
    try:
        obs = fred_obs(series_id, FRED_API_KEY, {"frequency": frequency.lower()})
    except requests.HTTPError as e:
        if e.response.status_code == 400 and frequency != "d":
            logger.warning(f"FRED –≤–µ—Ä–Ω—É–ª 400 –¥–ª—è {series_id} —Å frequency={frequency}, –ø—Ä–æ–±—É–µ–º –±–µ–∑ frequency")
            obs = fred_obs(series_id, FRED_API_KEY)  # –ë–µ–∑ frequency
        else:
            raise
    
    if not obs:
        logger.warning(f"FRED –≤–µ—Ä–Ω—É–ª 0 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –¥–ª—è {series_id}")
        return 0
    
    df = pd.DataFrame(obs).rename(columns={"date": "obs_date"})
    df["value"] = pd.to_numeric(df["value"], errors="coerce")
    df["is_sa"] = sa
    df["frequency"] = frequency
    df["series_id"] = series_id
    
    sql = text("""
        insert into stg_fred_series(series_id, obs_date, value, is_sa, frequency)
        values(:series_id, :obs_date, :value, :is_sa, :frequency)
        on conflict(series_id, obs_date) do update set
            value=excluded.value, is_sa=excluded.is_sa, frequency=excluded.frequency
    """)
    
    with engine.begin() as conn:
        for rec in df[["series_id", "obs_date", "value", "is_sa", "frequency"]].to_dict("records"):
            conn.execute(sql, rec)
    
    return len(df)

# ---------- HUD API ----------
@retry(
    stop=stop_after_attempt(3), 
    wait=wait_exponential(multiplier=1, max=8),
    retry=retry_if_exception_type(requests.RequestException)
)
def hud_get(endpoint: str, params: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ HUD API —Å Bearer-—Ç–æ–∫–µ–Ω–æ–º"""
    if not HUD_API_KEY:
        logger.info(f"HUD_API_KEY –ø—É—Å—Ç–æ–π; –ø—Ä–æ–ø—É—Å–∫–∞–µ–º endpoint {endpoint}")
        return {"data": []}
    
    headers = {"Authorization": f"Bearer {HUD_API_KEY}"}
    url = f"https://www.huduser.gov/hudapi/public/{endpoint}"
    
    try:
        r = requests.get(url, headers=headers, params=params or {}, timeout=REQUESTS_TIMEOUT_SECONDS)
        r.raise_for_status()
        return r.json()
    except requests.HTTPError as e:
        if e.response.status_code == 404:
            logger.warning(f"HUD API 404 –¥–ª—è {endpoint}: {e}")
            return {"data": []}
        else:
            raise

def ingest_hud_fmr(year: int = 2024) -> int:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö FMR –∏–∑ HUD —Å fallback –Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –≥–æ–¥—ã"""
    try:
        js = hud_get("fmr", {"year": year})
        rows = js.get("data") or js.get("results") or []
        
        if not rows:
            # –ü—Ä–æ–±—É–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –≥–æ–¥—ã
            for fallback_year in [year-1, year-2, year-3]:
                logger.warning(f"HUD FMR {year} –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–±—É–µ–º {fallback_year}")
                js = hud_get("fmr", {"year": fallback_year})
                rows = js.get("data") or js.get("results") or []
                if rows:
                    break
            
            if not rows:
                logger.warning(f"HUD FMR –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è {year}-{year-3}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                return 0
        
        df = pd.json_normalize(rows)
        ins = text("""
            insert into stg_hud_fmr(geo_code, geo_type, year, fmr_0, fmr_1, fmr_2, fmr_3, fmr_4)
            values(:geo_code, :geo_type, :year, :fmr_0, :fmr_1, :fmr_2, :fmr_3, :fmr_4)
            on conflict do nothing
        """)
        
        with engine.begin() as conn:
            for r in df.to_dict("records"):
                payload = {
                    "geo_code": str(r.get("geoid") or r.get("code") or r.get("fips") or ""),
                    "geo_type": str(r.get("geotype") or r.get("geo_type") or ""),
                    "year": int(r.get("year") or year),
                    "fmr_0": r.get("fmr0") or r.get("efficiency"),
                    "fmr_1": r.get("fmr1"),
                    "fmr_2": r.get("fmr2"),
                    "fmr_3": r.get("fmr_3"),
                    "fmr_4": r.get("fmr4"),
                }
                conn.execute(ins, payload)
        
        return len(df)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ HUD FMR: {e}")
        return 0

def ingest_hud_chas(year: int = 2021) -> int:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö CHAS –∏–∑ HUD —Å fallback –Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –≥–æ–¥—ã"""
    try:
        js = hud_get("chas", {"year": year})
        rows = js.get("data") or js.get("results") or []
        
        if not rows:
            # –ü—Ä–æ–±—É–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –≥–æ–¥—ã
            for fallback_year in [year-1, year-2, year-3]:
                logger.warning(f"HUD CHAS {year} –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–±—É–µ–º {fallback_year}")
                js = hud_get("chas", {"year": fallback_year})
                rows = js.get("data") or js.get("results") or []
                if rows:
                    break
            
            if not rows:
                logger.warning(f"HUD CHAS –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è {year}-{year-3}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                return 0
        
        df = pd.json_normalize(rows)
        ins = text("""
            insert into stg_hud_chas(geo_code, year, households_total, cost_burden_30, cost_burden_50, severe_shortage)
            values(:geo_code, :year, :households_total, :cost_burden_30, :cost_burden_50, :severe_shortage)
            on conflict do nothing
        """)
        
        with engine.begin() as conn:
            for r in df.to_dict("records"):
                payload = {
                    "geo_code": str(r.get("geoid") or r.get("fips") or ""),
                    "year": int(r.get("year") or year),
                    "households_total": r.get("households_total") or r.get("hh_total"),
                    "cost_burden_30": r.get("cost_burden_30") or r.get("hh_cb_30"),
                    "cost_burden_50": r.get("cost_burden_50") or r.get("hh_cb_50"),
                    "severe_shortage": r.get("severe_shortage") or r.get("shortage_severe"),
                }
                conn.execute(ins, payload)
        
        return len(df)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ HUD CHAS: {e}")
        return 0

# ---------- BEA API ----------
@retry(
    stop=stop_after_attempt(3), 
    wait=wait_exponential(multiplier=1, max=8),
    retry=retry_if_exception_type(requests.RequestException)
)
def bea_get(dataset: str, params: Dict[str, Any]) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ BEA API"""
    if not BEA_API_KEY:
        logger.info("BEA_API_KEY –ø—É—Å—Ç–æ–π; –ø—Ä–æ–ø—É—Å–∫–∞–µ–º BEA")
        return {}
    
    url = "https://apps.bea.gov/api/data"
    p = {
        "UserID": BEA_API_KEY, 
        "method": "GetData", 
        "datasetname": dataset, 
        "ResultFormat": "JSON"
    }
    p.update(params)
    
    r = requests.get(url, params=p, timeout=REQUESTS_TIMEOUT_SECONDS)
    r.raise_for_status()
    return r.json()

def ingest_bea_gdp() -> int:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö GDP –∏–∑ BEA NIPA"""
    try:
        js = bea_get("NIPA", {"TableName": "T10101", "Frequency": "Q"})
        series = (js.get("BEAAPI", {}) or {}).get("Results", {}).get("Data", [])
        
        if not series:
            logger.warning("BEA GDP –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return 0
        
        df = pd.DataFrame(series)
        ins = text("""
            insert into stg_bea_gdp(series, time_period, value, unit)
            values(:series, :time_period, :value, :unit)
            on conflict do nothing
        """)
        
        with engine.begin() as conn:
            for r in df.to_dict("records"):
                # –û—á–∏—Å—Ç–∫–∞ DataValue –æ—Ç –∑–∞–ø—è—Ç—ã—Ö
                data_value = str(r.get("DataValue", "0")).replace(",", "") if r.get("DataValue") else "0"
                payload = {
                    "series": str(r.get("SeriesCode") or "GDP"),
                    "time_period": str(r.get("TimePeriod")),
                    "value": float(data_value) if data_value != "0" else None,
                    "unit": str(r.get("UnitOfMeasure") or ""),
                }
                conn.execute(ins, payload)
        
        return len(df)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ BEA GDP: {e}")
        return 0

# ---------- BLS API ----------
@retry(
    stop=stop_after_attempt(3), 
    wait=wait_exponential(multiplier=1, max=8),
    retry=retry_if_exception_type(requests.RequestException)
)
def bls_post(series_ids: List[str], start_year: int = 2019, end_year: int = 2025) -> Dict[str, Any]:
    """POST-–∑–∞–ø—Ä–æ—Å –∫ BLS API"""
    url = "https://api.bls.gov/publicAPI/v2/timeseries/data/"
    payload = {
        "seriesid": series_ids, 
        "startyear": str(start_year), 
        "endyear": str(end_year)
    }
    
    if BLS_API_KEY:
        payload["registrationkey"] = BLS_API_KEY
    
    r = requests.post(url, json=payload, timeout=REQUESTS_TIMEOUT_SECONDS)
    r.raise_for_status()
    return r.json()

def ingest_bls_cpi(series_id: str = "CUSR0000SA0", start_year: int = 2019, end_year: int = 2025) -> int:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö CPI –∏–∑ BLS"""
    try:
        js = bls_post([series_id], start_year, end_year)
        data = js.get("Results", {}).get("series", [])
        
        if not data:
            logger.warning("BLS CPI –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return 0
        
        obs = data[0].get("data", [])
        df = pd.DataFrame(obs)
        ins = text("""
            insert into stg_bls_cpi(series_id, year, period, value)
            values(:series_id, :year, :period, :value)
            on conflict do nothing
        """)
        
        with engine.begin() as conn:
            for r in df.to_dict("records"):
                payload = {
                    "series_id": series_id, 
                    "year": int(r["year"]), 
                    "period": r["period"], 
                    "value": float(r["value"])
                }
                conn.execute(ins, payload)
        
        return len(df)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ BLS CPI: {e}")
        return 0

# ---------- Census API ----------
@retry(
    stop=stop_after_attempt(3), 
    wait=wait_exponential(multiplier=1, max=8),
    retry=retry_if_exception_type(requests.RequestException)
)
def census_get(year: int, dataset: str, variables: List[str], geo: str = "us:1") -> List[List[str]]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Census API"""
    if not CENSUS_API_KEY:
        logger.info("CENSUS_API_KEY –ø—É—Å—Ç–æ–π; –ø—Ä–æ–ø—É—Å–∫–∞–µ–º Census")
        return []
    
    base = f"https://api.census.gov/data/{year}/{dataset}"
    get_vars = ",".join(variables)
    params = {"get": get_vars, "for": geo, "key": CENSUS_API_KEY}
    
    r = requests.get(base, params=params, timeout=REQUESTS_TIMEOUT_SECONDS)
    r.raise_for_status()
    return r.json()  # –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ - –∑–∞–≥–æ–ª–æ–≤–æ–∫

def ingest_census_acs(year: int = 2023) -> int:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ACS –∏–∑ Census (–º–µ–¥–∏–∞–Ω–Ω–∞—è —Ä–µ–Ω—Ç–∞ –∏ —Å—Ç–æ–∏–º–æ—Å—Ç—å –∂–∏–ª—å—è)"""
    try:
        rows = census_get(year, "acs/acs1", ["B25064_001E", "B25077_001E", "NAME"], "us:1")
        
        if not rows:
            logger.warning(f"Census ACS {year} –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return 0
        
        header, *data = rows
        cols = {name: idx for idx, name in enumerate(header)}
        idx_rent = cols.get("B25064_001E")
        idx_value = cols.get("B25077_001E")
        idx_name = cols.get("NAME")
        idx_state = cols.get("us") if "us" in cols else None

        ins = text("""
            insert into stg_census_acs(year, geo, var_code, value)
            values(:year, :geo, :var_code, :value)
            on conflict do nothing
        """)
        
        with engine.begin() as conn:
            for row in data:
                geo = f"us:{row[idx_state]}" if idx_state is not None else "us:1"
                
                if idx_rent is not None:
                    try:
                        val = float(row[idx_rent])
                    except (ValueError, TypeError):
                        val = None
                    conn.execute(ins, {"year": year, "geo": geo, "var_code": "B25064_001E", "value": val})
                
                if idx_value is not None:
                    try:
                        val2 = float(row[idx_value])
                    except (ValueError, TypeError):
                        val2 = None
                    conn.execute(ins, {"year": year, "geo": geo, "var_code": "B25077_001E", "value": val2})
        
        return len(data)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Census ACS: {e}")
        return 0

# ---------- DWH helpers ----------
def seed_date_dimension() -> None:
    """–ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –∏–∑–º–µ—Ä–µ–Ω–∏—è –¥–∞—Ç —Å 1940 –≥–æ–¥–∞ –¥–ª—è –ø–æ–∫—Ä—ã—Ç–∏—è –≤—Å–µ—Ö –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö FRED"""
    sql = """
    insert into dwh_dim_date(date_key, date_value, year, quarter, month, week, day, is_month_end, is_quarter_end)
    select
        cast(to_char(d, 'YYYYMMDD') as int),
        d,
        extract(year from d)::smallint,
        extract(quarter from d)::smallint,
        extract(month from d)::smallint,
        extract(week from d)::smallint,
        extract(day from d)::smallint,
        (d = (date_trunc('month', d) + interval '1 month - 1 day')::date),
        (d = (date_trunc('quarter', d) + interval '3 month - 1 day')::date)
    from generate_series(date '1940-01-01', date '2035-12-31', interval '1 day') as gs(d)
    on conflict (date_key) do nothing;
    """
    with engine.begin() as conn:
        conn.execute(text(sql))
    logger.info("‚úì –ò–∑–º–µ—Ä–µ–Ω–∏–µ –¥–∞—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ (1940-2035)")

def upsert_series_meta() -> None:
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å–µ—Ä–∏–π"""
    sql = """
    insert into dwh_dim_series(series_id, series_name, unit, seasonal, frequency, source) values
      ('MORTGAGE30US','30Y Fixed Mortgage Rate','percent','NSA','W','FRED'),
      ('CPIAUCSL','CPI All Urban Consumers','index','SA','M','FRED'),
      ('UNRATE','Unemployment Rate','percent','SA','M','FRED')
    on conflict (series_id) do nothing;
    """
    with engine.begin() as conn:
        conn.execute(text(sql))
    logger.info("‚úì –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–µ—Ä–∏–π –æ–±–Ω–æ–≤–ª–µ–Ω—ã")

def conform_mortgage_rates() -> None:
    """–ö–æ–Ω—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ –∏–ø–æ—Ç–µ—á–Ω—ã–º —Å—Ç–∞–≤–∫–∞–º —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ –¥–∞—Ç–∞–º"""
    sql = """
    insert into dwh_fact_mortgage_rates(date_key, series_key, rate)
    select 
        cast(to_char(obs_date, 'YYYYMMDD') as int),
        (select series_key from dwh_dim_series where series_id='MORTGAGE30US'),
        value::numeric
    from stg_fred_series
    where series_id='MORTGAGE30US'
    and obs_date >= '1940-01-01'
    and obs_date <= '2035-12-31'
    on conflict do nothing;
    """
    with engine.begin() as conn:
        conn.execute(text(sql))
    logger.info("‚úì –§–∞–∫—Ç—ã –ø–æ –∏–ø–æ—Ç–µ—á–Ω—ã–º —Å—Ç–∞–≤–∫–∞–º –∑–∞–≥—Ä—É–∂–µ–Ω—ã")

def conform_cpi_from_fred() -> None:
    """–ö–æ–Ω—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ CPI –∏–∑ FRED —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ –¥–∞—Ç–∞–º"""
    sql = """
    insert into dwh_fact_cpi(date_key, cpi)
    select 
        cast(to_char(obs_date,'YYYYMMDD') as int), 
        value::numeric
    from stg_fred_series
    where series_id='CPIAUCSL'
    and obs_date >= '1940-01-01'
    and obs_date <= '2035-12-31'
    on conflict do nothing;
    """
    with engine.begin() as conn:
        conn.execute(text(sql))
    logger.info("‚úì –§–∞–∫—Ç—ã CPI –∑–∞–≥—Ä—É–∂–µ–Ω—ã")

def conform_unemployment_from_fred() -> None:
    """–ö–æ–Ω—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ –±–µ–∑—Ä–∞–±–æ—Ç–∏—Ü–µ –∏–∑ FRED —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ –¥–∞—Ç–∞–º"""
    sql = """
    insert into dwh_fact_unemployment(date_key, unemp_rate)
    select 
        cast(to_char(obs_date,'YYYYMMDD') as int), 
        value::numeric
    from stg_fred_series
    where series_id='UNRATE'
    and obs_date >= '1940-01-01'
    and obs_date <= '2035-12-31'
    on conflict do nothing;
    """
    with engine.begin() as conn:
        conn.execute(text(sql))
    logger.info("‚úì –§–∞–∫—Ç—ã –ø–æ –±–µ–∑—Ä–∞–±–æ—Ç–∏—Ü–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")

def main() -> None:
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è ETL-–ø–∞–π–ø–ª–∞–π–Ω–∞"""
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ Real Estate Analytics Pipeline v2")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ö–µ–º –∏ —Ç–∞–±–ª–∏—Ü
    ensure_core()
    ensure_staging_tables()
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    total_fred = 0
    total_fred += ingest_fred("MORTGAGE30US", "w", False)
    total_fred += ingest_fred("CPIAUCSL", "m", True)
    total_fred += ingest_fred("UNRATE", "m", True)
    logger.info(f"üìä FRED –∑–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {total_fred}")
    
    fmr_count = ingest_hud_fmr(2024)
    chas_count = ingest_hud_chas(2021)
    logger.info(f"üè† HUD FMR –∑–∞–ø–∏—Å–µ–π: {fmr_count} | HUD CHAS –∑–∞–ø–∏—Å–µ–π: {chas_count}")
    
    bea_count = ingest_bea_gdp()
    bls_count = ingest_bls_cpi()
    logger.info(f"üìà BEA GDP –∑–∞–ø–∏—Å–µ–π: {bea_count} | BLS CPI –∑–∞–ø–∏—Å–µ–π: {bls_count}")
    
    acs_count = ingest_census_acs(2023)
    logger.info(f"üèòÔ∏è Census ACS –∑–∞–ø–∏—Å–µ–π: {acs_count}")
    
    # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ DWH
    seed_date_dimension()
    upsert_series_meta()
    conform_mortgage_rates()
    conform_cpi_from_fred()
    conform_unemployment_from_fred()
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —Å–≤–æ–¥–∫–∞
    total_records = total_fred + fmr_count + chas_count + bea_count + bls_count + acs_count
    logger.info(f"‚úÖ Pipeline finished successfully. –í—Å–µ–≥–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {total_records}")

if __name__ == "__main__":
    main()
